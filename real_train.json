[{"loss": 1.5687, "grad_norm": 0.5265970826148987, "learning_rate": 0.0, "epoch": 0.016, "step": 1}, {"loss": 1.8566, "grad_norm": 0.7329677939414978, "learning_rate": 4e-05, "epoch": 0.032, "step": 2}, {"loss": 2.3362, "grad_norm": 1.00596022605896, "learning_rate": 8e-05, "epoch": 0.048, "step": 3}, {"loss": 1.9083, "grad_norm": 0.8230272531509399, "learning_rate": 0.00012, "epoch": 0.064, "step": 4}, {"loss": 1.6987, "grad_norm": 0.5678889155387878, "learning_rate": 0.00016, "epoch": 0.08, "step": 5}, {"loss": 1.4158, "grad_norm": 1.1627135276794434, "learning_rate": 0.0002, "epoch": 0.096, "step": 6}, {"loss": 1.1919, "grad_norm": 0.7944719195365906, "learning_rate": 0.00019636363636363636, "epoch": 0.112, "step": 7}, {"loss": 1.0054, "grad_norm": 0.6014798879623413, "learning_rate": 0.00019272727272727274, "epoch": 0.128, "step": 8}, {"loss": 0.9844, "grad_norm": 0.5232914686203003, "learning_rate": 0.0001890909090909091, "epoch": 0.144, "step": 9}, {"loss": 0.8197, "grad_norm": 0.430302232503891, "learning_rate": 0.00018545454545454545, "epoch": 0.16, "step": 10}, {"loss": 0.964, "grad_norm": 0.4165691137313843, "learning_rate": 0.00018181818181818183, "epoch": 0.176, "step": 11}, {"loss": 0.8013, "grad_norm": 0.5870522260665894, "learning_rate": 0.0001781818181818182, "epoch": 0.192, "step": 12}, {"loss": 1.0427, "grad_norm": 0.8143019676208496, "learning_rate": 0.00017454545454545454, "epoch": 0.208, "step": 13}, {"loss": 0.8923, "grad_norm": 0.8173010349273682, "learning_rate": 0.0001709090909090909, "epoch": 0.224, "step": 14}, {"loss": 1.1202, "grad_norm": 0.39919352531433105, "learning_rate": 0.00016727272727272728, "epoch": 0.24, "step": 15}, {"loss": 0.9053, "grad_norm": 0.6235675811767578, "learning_rate": 0.00016363636363636366, "epoch": 0.256, "step": 16}, {"loss": 0.9814, "grad_norm": 0.5263532996177673, "learning_rate": 0.00016, "epoch": 0.272, "step": 17}, {"loss": 1.0295, "grad_norm": 0.7071881294250488, "learning_rate": 0.00015636363636363637, "epoch": 0.288, "step": 18}, {"loss": 1.2072, "grad_norm": 0.5849632024765015, "learning_rate": 0.00015272727272727275, "epoch": 0.304, "step": 19}, {"loss": 0.825, "grad_norm": 0.7090822458267212, "learning_rate": 0.0001490909090909091, "epoch": 0.32, "step": 20}, {"loss": 0.8716, "grad_norm": 0.7401869893074036, "learning_rate": 0.00014545454545454546, "epoch": 0.336, "step": 21}, {"loss": 0.8705, "grad_norm": 0.35315728187561035, "learning_rate": 0.00014181818181818184, "epoch": 0.352, "step": 22}, {"loss": 0.8796, "grad_norm": 0.3463728129863739, "learning_rate": 0.0001381818181818182, "epoch": 0.368, "step": 23}, {"loss": 0.9258, "grad_norm": 0.3406519591808319, "learning_rate": 0.00013454545454545455, "epoch": 0.384, "step": 24}, {"loss": 0.8934, "grad_norm": 0.40626272559165955, "learning_rate": 0.00013090909090909093, "epoch": 0.4, "step": 25}, {"loss": 0.9102, "grad_norm": 0.3669028878211975, "learning_rate": 0.00012727272727272728, "epoch": 0.416, "step": 26}, {"loss": 0.873, "grad_norm": 0.3838651478290558, "learning_rate": 0.00012363636363636364, "epoch": 0.432, "step": 27}, {"loss": 1.257, "grad_norm": 0.37519246339797974, "learning_rate": 0.00012, "epoch": 0.448, "step": 28}, {"loss": 1.028, "grad_norm": 0.35330477356910706, "learning_rate": 0.00011636363636363636, "epoch": 0.464, "step": 29}, {"loss": 0.8654, "grad_norm": 0.32751768827438354, "learning_rate": 0.00011272727272727272, "epoch": 0.48, "step": 30}, {"loss": 0.8677, "grad_norm": 0.444219172000885, "learning_rate": 0.00010909090909090909, "epoch": 0.496, "step": 31}, {"loss": 0.7545, "grad_norm": 0.3873160779476166, "learning_rate": 0.00010545454545454545, "epoch": 0.512, "step": 32}, {"loss": 1.1967, "grad_norm": 0.3926772177219391, "learning_rate": 0.00010181818181818181, "epoch": 0.528, "step": 33}, {"loss": 0.8938, "grad_norm": 0.297656387090683, "learning_rate": 9.818181818181818e-05, "epoch": 0.544, "step": 34}, {"loss": 0.9379, "grad_norm": 0.30696719884872437, "learning_rate": 9.454545454545455e-05, "epoch": 0.56, "step": 35}, {"loss": 1.3796, "grad_norm": 0.4149553179740906, "learning_rate": 9.090909090909092e-05, "epoch": 0.576, "step": 36}, {"loss": 0.9908, "grad_norm": 0.44130179286003113, "learning_rate": 8.727272727272727e-05, "epoch": 0.592, "step": 37}, {"loss": 0.8856, "grad_norm": 0.32187122106552124, "learning_rate": 8.363636363636364e-05, "epoch": 0.608, "step": 38}, {"loss": 0.8749, "grad_norm": 0.32274308800697327, "learning_rate": 8e-05, "epoch": 0.624, "step": 39}, {"loss": 0.8633, "grad_norm": 0.3089684844017029, "learning_rate": 7.636363636363637e-05, "epoch": 0.64, "step": 40}, {"loss": 0.8952, "grad_norm": 0.447634756565094, "learning_rate": 7.272727272727273e-05, "epoch": 0.656, "step": 41}, {"loss": 0.87, "grad_norm": 0.27737560868263245, "learning_rate": 6.90909090909091e-05, "epoch": 0.672, "step": 42}, {"loss": 0.844, "grad_norm": 0.33520135283470154, "learning_rate": 6.545454545454546e-05, "epoch": 0.688, "step": 43}, {"loss": 0.7008, "grad_norm": 0.33929142355918884, "learning_rate": 6.181818181818182e-05, "epoch": 0.704, "step": 44}, {"loss": 1.149, "grad_norm": 0.36676138639450073, "learning_rate": 5.818181818181818e-05, "epoch": 0.72, "step": 45}, {"loss": 0.8502, "grad_norm": 0.363750696182251, "learning_rate": 5.4545454545454546e-05, "epoch": 0.736, "step": 46}, {"loss": 0.799, "grad_norm": 0.4317946135997772, "learning_rate": 5.090909090909091e-05, "epoch": 0.752, "step": 47}, {"loss": 0.9152, "grad_norm": 0.3153688907623291, "learning_rate": 4.7272727272727275e-05, "epoch": 0.768, "step": 48}, {"loss": 1.0032, "grad_norm": 0.6685411334037781, "learning_rate": 4.3636363636363636e-05, "epoch": 0.784, "step": 49}, {"loss": 0.8177, "grad_norm": 0.44503965973854065, "learning_rate": 4e-05, "epoch": 0.8, "step": 50}, {"loss": 0.981, "grad_norm": 0.3759444057941437, "learning_rate": 3.6363636363636364e-05, "epoch": 0.816, "step": 51}, {"loss": 0.9419, "grad_norm": 0.3920242190361023, "learning_rate": 3.272727272727273e-05, "epoch": 0.832, "step": 52}, {"loss": 1.0085, "grad_norm": 0.49331921339035034, "learning_rate": 2.909090909090909e-05, "epoch": 0.848, "step": 53}, {"loss": 1.2424, "grad_norm": 0.35081759095191956, "learning_rate": 2.5454545454545454e-05, "epoch": 0.864, "step": 54}, {"loss": 0.8914, "grad_norm": 0.35943713784217834, "learning_rate": 2.1818181818181818e-05, "epoch": 0.88, "step": 55}, {"loss": 0.9284, "grad_norm": 0.3405643701553345, "learning_rate": 1.8181818181818182e-05, "epoch": 0.896, "step": 56}, {"loss": 1.0192, "grad_norm": 0.36337292194366455, "learning_rate": 1.4545454545454545e-05, "epoch": 0.912, "step": 57}, {"loss": 1.0076, "grad_norm": 0.3073219656944275, "learning_rate": 1.0909090909090909e-05, "epoch": 0.928, "step": 58}, {"loss": 0.8179, "grad_norm": 0.29617851972579956, "learning_rate": 7.272727272727272e-06, "epoch": 0.944, "step": 59}, {"loss": 0.7682, "grad_norm": 0.3919532597064972, "learning_rate": 3.636363636363636e-06, "epoch": 0.96, "step": 60}, {"train_runtime": 348.9907, "train_samples_per_second": 1.375, "train_steps_per_second": 0.172, "total_flos": 3831876799561728.0, "train_loss": 1.033749243617058, "epoch": 0.96, "step": 60}]